<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Research Areas</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/simplex.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Kun Xu website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">About Me</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="publications.html">Publications</a>
</li>
<li>
  <a href="PAILab.html">PAI Lab</a>
</li>
<li>
  <a href="teaching.html">Teaching</a>
</li>
<li>
  <a href="media.html">Media &amp; Talks</a>
</li>
<li>
  <a href="cv.html">CV</a>
</li>
<li>
  <a href="contact.html">Contact/中文</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="mailto:&lt;kun.xu@ufl.edu&gt;">
    <span class="fa fa-envelope fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://scholar.google.com/citations?user=ojzP8I0AAAAJ&amp;hl=en">
    <span class="fa fa-google fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/bigben219">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/xkunnet">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/kun-xu/">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Research Areas</h1>

</div>


<p><br> <br></p>
<p><font color="green">Latest update: 6/1/2025</font></p>
<p>I identify myself as an HCI scholar who focuses on the roles of
social cues and social presence in individuals’ psychological processing
of emerging technologies, including humanoid social robots and
virtual/augmented agents. To be more specific, my research investigates
how and why various combinations of social cues designed into AI-based
technologies evoke users’ social responses, including their perceptions
of technologies as social entities (i.e., social presence), their trust
in technologies, and their compliance with/conformity to technologies. I
am also broadly interested in Science and Technology Studies (STS) and
seek to understand the mutual shaping between humans and machines.</p>
<p>I was honored and lucky to have been mentored by two great scholars
in the areas of presence and virtual/augmented reality: <a
href="https://klein.temple.edu/faculty/matthew-lombard">Dr. Matthew
Lombard</a> and <a
href="https://dot.egr.uh.edu/departments/ilt/people/faculty/liao-tony">Dr. Tony
Liao</a>.</p>
<p><br> <br></p>
<p><font color="green"><strong>My research program subsumes three
general directions:</strong></font></p>
<p>[1] Testing and extending the Computers are Social Actors (CASA)
paradigm to the Media are Social Actors (MASA) paradigm;</p>
<p>[2] Testing and developing a framework that integrates interpersonal
communication, human-computer interaction, and computer-mediated
communication to better understand AI technologies;</p>
<p>[3] Bridging communication research with explainable AI and
understanding how various explanation components affect individuals’
decision-making in human-AI interactions.</p>
<p><br> <br></p>
<p><font color="green"><strong>[1] Testing and extending the Computers
are Social Actors (CASA) paradigm to the Media are Social Actors (MASA)
paradigm:</strong></font></p>
<p><img src="images/masa2.png" /></p>
<p>This first line of my research seeks to update and extend the classic
HCI framework, the Computers Are Social Actors (CASA) paradigm. This
paradigm has been widely applied to predict how users mindlessly apply
some of the social scripts of interpersonal communication to HCI.
However, some gaps remain to be filled in past CASA literature: 1) what
social cues exert stronger effects than others in evoking users’ social
responses, 2) what mechanism best explains users’ psychological
responses to technologies, and 3) how “social” a technology can be to
bring forth users’ mindless social responses. Therefore, my works extend
this paradigm to a more structured and proposition-based framework, the
Media Are Social Actors (MASA) paradigm, by distinguishing the effects
of single social cues designed into technologies, identifying the
application contingencies of mindless anthropomorphism and mindful
anthropomorphism as two major explanatory architectures, and drawing on
evolutionary psychology to build the foundation for the paradigm. This
new theoretical framework lists testable propositions that allow
scholars to derive hypotheses and research questions in future AI
research.</p>
<p><img src="images/robot.png" /> <img
src="images/multidimensional.png" /></p>
<p><u>Relevant publications:</u></p>
<p>Lombard, M., &amp; Xu, K. (corresponding author) (2021). Social
responses to media technologies: The Media are Social Actors paradigm.
<em>Human-Machine Communication, 2,</em> 29-55. <a
href="publications/Lombard%20&amp;%20Xu%202021%20Social%20Responses%20to%20Media%20Technologies%20in%20the%2021st%20Century_%20The%20M.pdf">PDF</a></p>
<p>Xu, K. (2019). First encounter with robot Alpha: How individual
differences interact with vocal and kinetic cues in users’ social
responses. <em>New Media &amp; Society, 21,</em> 2522-2547. <a
href="publications/Xu%202019%20Robot%20alpha.pdf">PDF</a></p>
<p>Xu, K. (2020). Language, modality, and mobile media use experiences:
Social responses to smartphone cues in a task-oriented context.
<em>Telematics and Informatics, 48,</em> 101344 <a
href="publications/Xu%202020%20Mobile%20phone%20study.pdf">PDF</a></p>
<p>Xu, K., Chen, M., &amp; You, L. (2023). The hitchhiker’s guide to a
credible and socially present robot: Two meta-analyses of the power of
social cues in human-robot interaction. <em>International Journal of
Social Robotics.</em> <a
href="publications/Xu%20et%20al.%202023%20Meta-Analyses.pdf">PDF</a></p>
<p>Xu, K., Chen, X., &amp; Huang, L. (2022). Deep mind in social
responses to technologies: A new approach to explaining the Computers
are Social Actors phenomena. <em>Computers in Human Behavior, 134,</em>
107321. <a
href="publications/Xu%20et%20al.%202022%20Deep%20mind%20in%20social%20responses.pdf">PDF</a></p>
<p><br> <br></p>
<p><font color="green"><strong>[2] Testing and developing a framework
that integrates interpersonal communication, HCI, and computer-mediated
communication (CMC):</strong></font></p>
<p><img src="images/JCMC.png" /></p>
<p>While the development of the MASA paradigm focuses on the effects of
human social cues (e.g., human appearances, human voices, gestures)
designed into technologies, the second line of my research develops a
theoretical framework that explicates different types of cues presented
by emerging technologies. For example, users may interact with a
telepresence robot through cues presented by both the technology per se
(e.g., robotic movements) and the remote human user (e.g., facial
expressions). Virtual/augmented reality (VR/AR) technologies allow users
to interact with the verbal and non-verbal cues of virtual agents within
the immersive/augmented environments as well as the force and touch
feedback cues delivered by the controllers. Although chatbots use human
language, they vary in response delays and the use of emojis, memes,
message receipts, and other CMC components. Given that these
telepresence robots, VR/AR technologies, and chatbots have blurred the
traditional boundaries of HCI and CMC, and hence challenged the existing
conceptualizations of mediation, intelligence, and reality, this line of
research pursues the integration of core concepts/theories across the
fields of HCI, interpersonal communication, and CMC. In a special issue
examining the future state of CMC, my research proposed a typology of
cues (i.e., cues as social signals, message elements, social categories,
affordances) to better understand future human-technology relationships.
This typology seeks to bridge theories from different fields to
understand convergent technologies that deliver both human social cues
and machine-generated social cues at the same time.</p>
<p><img src="images/robot%20transparency.png" /></p>
<p><img src="images/garbagerecycle.png" /></p>
<p><u>Relevant publications:</u></p>
<p>Xu, K., &amp; Liao, T. (2020). Explicating cues: A typology for
understanding emerging media technologies. <em>Journal of
Computer-Mediated Communication, 25,</em> 32-43. <a
href="publications/Xu%20&amp;%20Liao%20Explicating%20Cues%20JCMC.pdf">PDF</a>;
<a href="publications/ICA%20paper%205.30%20Kun%20&amp;%20Tony.pdf">Long
Version</a></p>
<p>Xu, K., Chen, X., Liu, F., &amp; Huang, L. (2024). What did you hear
and what did you see? Understanding the transparency of facial
recognition and speech recognition systems during human-robot
interaction. <em>New Media &amp; Society.</em> Online First. <a
href="publications/xu-et-al-2024-what-did-you-hear-and-what-did-you-see-understanding-the-transparency-of-facial-recognition-and-speech.pdf">PDF</a></p>
<p>Xu, K., &amp; Lombard, M. (2017). Persuasive computing: Feeling peer
pressure from multiple computer agents. <em>Computers in Human Behavior,
74,</em> 152-162. <a
href="publications/Xu_Lombard_Persuasive%20computing.pdf">PDF</a></p>
<p>Xu, K. (2023). A mini imitation game: How individuals model social
robots via behavioral outcomes and social roles. <em>Telematics &amp;
Informatics, 78,</em> 101950. <a
href="publications/Xu%202023%20mini%20imitation%20game.pdf">PDF</a></p>
<p><br> <br></p>
<p><font color="green"><strong>[3] Bridging communication research with
explainable AI and understanding how various explanation components
affect individuals’ decision-making in human-AI
interactions:</strong></font></p>
<p>The third line concentrates on XAI and examines how various forms of
explanations about algorithms may affect users’ attitudes toward AI-made
decisions. Given that AI-based technologies are becoming more automatic,
multi-layered, and ubiquitous, explanations of the working mechanisms of
these technologies, especially concerning the role of human intervention
and human verification in the algorithms of these technologies, will be
pivotal in fostering our theorization of AI. This line of work will
provide insights into how individuals may engage in a two-level
communication process, where the content and the forms of the
explanations of AI systems will serve as an additional meaning-making
process and merge with the first-level meaning-making between humans and
AI systems. Building on my prior work on cues and human-centered AI, I
anticipate that these two lines of research will continue to inform
areas such as user interface design, education, health intervention,
teleconferencing, as well as shed light on the philosophical and
methodological discussions about human-technology relationships.</p>
<p> </p>
<p><img src="images/XAI.png" /></p>
<p><br></p>
<p><u>Relevant publications:</u></p>
<p>Xu, K., &amp; Shi, J. (2024). Visioning a two-level human-machine
communication framework: Initiating conversations between explainable AI
and communication. <em>Communication Theory, 34,</em> 216-229. <a
href="publications/Xu%20&amp;%20Shi%202024%20XAI%20&amp;%20communication.pdf">PDF</a></p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
